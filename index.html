<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GV15VYJMQP"></script>
    <script>
      window.dataLayer = window.dataLayer || [];

      function gtag() {
        dataLayer.push(arguments);
      }

      gtag("js", new Date());
      gtag("config", "G-GV15VYJMQP");
    </script>

    <meta charset="utf-8" />
    <title>AI Training</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- import the webpage's stylesheet -->
    <link rel="stylesheet" href="/styles/index.css" />
    <link rel="icon" type="image/x-icon" href="/assets/favicon.ico" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Karla:wght@400;700&display=swap"
      rel="stylesheet"
    />

    <!-- TensorFlow.js Library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <!-- Socket.io -->
    <script
      src="https://cdn.socket.io/3.1.3/socket.io.min.js"
      integrity="sha384-cPwlPLvBTa3sKAgddT6krw0cJat7egBga3DJepJyrLl4Q9/5WLra3rrnMcyTyOnh"
      crossorigin="anonymous"
    ></script>
    <!-- Teachable Machine: tensorflow -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <!-- Teachable Machine: Image Recognition -->
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
    <!-- Teachable Machine: Audio Recognition -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>
    <!-- Teachable Machine: Pose Recognition -->
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
    <!-- Jquery -->
    <script
      src="https://code.jquery.com/jquery-3.6.0.min.js"
      integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4="
      crossorigin="anonymous"
    ></script>
    <!-- Jquery UI -->
    <script
      src="https://code.jquery.com/ui/1.13.0/jquery-ui.min.js"
      integrity="sha256-hlKLmzaRlE8SCJC1Kw8zoUbU8BxA+8kR3gseuKfMjxA="
      crossorigin="anonymous"
    ></script>
    <!-- Canvas Confetti -->
    <script src="https://cdn.jsdelivr.net/npm/canvas-confetti@1.4.0/dist/confetti.browser.min.js"></script>
  </head>

  <body>
    <div id="page-1">
      <div class="page-container">
        <h1>AI and Micro:bit Integration</h1>
        <p>Paste your Teachable Machine AI model link below and start:</p>

        <input
          id="teachableUrl"
          type="url"
          placeholder="https://teachablemachine.withgoogle.com/models/[...]"
          required
        />
        <button id="submitUrl">Ready!</button>

        <div id="status-container">
          <h2>Status: <span id="status">Awaiting AI Model</span></h2>
        </div>

        <div id="video-container" style="display: none;">
          <video id="webcam" autoplay></video>
          <h3>Prediction: <span id="prediction">None</span></h3>
          <progress id="prediction-progress" value="0" max="1"></progress>
        </div>
      </div>
    </div>

    <script>
      let model;
      const video = document.getElementById('webcam');
      const predictionText = document.getElementById('prediction');
      const predictionProgress = document.getElementById('prediction-progress');
      const statusText = document.getElementById('status');
      const videoContainer = document.getElementById('video-container');

      document.getElementById('submitUrl').addEventListener('click', async () => {
        const url = document.getElementById('teachableUrl').value;

        if (!url) {
          alert('Please provide a valid AI model URL.');
          return;
        }

        statusText.innerText = 'Loading AI Model...';

        try {
          model = await tf.loadGraphModel(url + '/model.json');
          statusText.innerText = 'AI Model Loaded Successfully!';
          videoContainer.style.display = 'block';
          setupCamera();
        } catch (error) {
          console.error('Error loading AI model:', error);
          statusText.innerText = 'Failed to Load AI Model';
          alert('Please check the AI model URL and try again.');
        }
      });

      async function setupCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: true });
          video.srcObject = stream;
          video.addEventListener('loadeddata', classifyFrame);
        } catch (error) {
          console.error('Error accessing webcam:', error);
          alert('Failed to access webcam. Please check permissions.');
        }
      }

      async function classifyFrame() {
        if (model) {
          const tensor = tf.browser.fromPixels(video).expandDims(0).toFloat();
          const predictions = await model.predict(tensor);

          const maxPrediction = predictions.dataSync()[0]; // Adjust index based on model output
          predictionText.innerText = maxPrediction.toFixed(2);
          predictionProgress.value = maxPrediction;
        }

        requestAnimationFrame(classifyFrame);
      }
    </script>

    <!-- Additional Scripts -->
    <script src="/scripts/serialConnection.js" type="text/javascript"></script>
    <script src="/scripts/imageRec.js" type="text/javascript"></script>
    <script src="/scripts/audioRec.js" type="text/javascript"></script>
    <script src="/scripts/poseRec.js" type="text/javascript"></script>
    <script src="/scripts/confetti.js" type="text/javascript"></script>
    <script src="/scripts/analytics.js" type="text/javascript"></script>
  </body>
</html>
